{"cells": [{"cell_type": "code", "metadata": {}, "source": ["import tensorflow as tf\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization, Input\n\n", "\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\n# Load Iris dataset\ndata = load_iris()\nX, y = data.data, data.target\n\n# Standardize features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# One-hot encode labels\nencoder = OneHotEncoder(sparse_output=False)\ny = encoder.fit_transform(y.reshape(-1, 1))\n\n# Split data\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n", "# Define the model\n", "model = Sequential([\n", "Input(shape=(4,)),\nDense(64, activation='relu'),\nDense(3, activation='softmax'),\n", "])\n\n", "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n", "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n", "model.save('trained_model.keras')\n"], "execution_count": null, "outputs": []}], "metadata": {}, "nbformat": 4, "nbformat_minor": 2}